<!DOCTYPE html>

<html>
<head>
  <script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
  <script src="js/recorder.js"></script>
  <style type='text/css'>
    ul { list-style: none; } audio { display: block; margin-bottom: 10px; }
  </style>
</head>
<body>
  
  <!-- STRUCTURE -->
  
  <button id="startRecognition">Mute (start recognition)</button>
  <button onClick="mute();">Mute (only)</button>
  
  <audio id="background1" preload="auto" autoplay loop volume="0.3" src="./files/test-1.wav"></audio>
  <audio id="background2" preload="auto" autoplay loop volume="0.3" src="./files/test-2.wav"></audio>
  
  <ul id="matchedSoundsList">
    
    <!-- Placeholder for all matched sounds -->
    
  </ul>
  
    
  <!-- APPLICATION -->
  
  <script type="text/javascript">
      
    ////////////////////////////////
    // SPEECH RECOGNITION
    // Supported only in Chrome
    // Once started, you need to allow Chrome to use the microphone
    ////////////////////////////////
    
    var love = false, hate = false;
    var recognition = new webkitSpeechRecognition();
    
    // Be default, Chrome will only return a single result.
    // By enabling "continuous", Chrome will keep the microphone active.
    recognition.continuous = false;
    
    // To get the results while speaking set to true
    recognition.interimResults = false;
    
    // Set language to Englisch (works without, but makes it faster)
    recognition.lang = 'en-US';
    
    // When Google sends back the result we can do the magic
    recognition.onresult = function(event) {
        // Get the current result from the results object
        var transcript = event.results[event.results.length-1][0].transcript;
        // Send the result string via WebSocket to the running Processing Sketch
        //ws.send(transcript);
        console.log("Result: " + transcript);
        
        // Stop recording and trigger upload
        upload(transcript);
    }
    
    // Controlling the whole thing
    // Start the recognition
    //recognition.start();
    // Start the recording when Chrome recognizes "speech"
    recognition.onspeechstart = function() { startRecording(); }
    // End the recording when the sound ends (try onsoundend too)
    recognition.onspeechend = function() { 
      recorder && recorder.stop();
      console.log('Stopped recording.');
    }
    
    $("#startRecognition").click(function(){
      destroy();
      mute();
      recognition.start();
    })
    
    
    ////////////////////////////////
    // RECORDING THE FILE
    // is triggered when the Speech Recognition will detect Speech
    ////////////////////////////////
    
    var audio_context;
    var recorder;
    
    // Enabling the recording functions
    window.onload = function init() {
      window.AudioContext = window.AudioContext || window.webkitAudioContext;
      navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia;
      window.URL = window.URL || window.webkitURL;
      
      audio_context = new AudioContext;
      
      navigator.getUserMedia({ audio: true }, startUserMedia, function(e){});
    };
    
    function startUserMedia(stream) {
      var input = audio_context.createMediaStreamSource(stream); 
      recorder = new Recorder(input);
    }

    function startRecording() {
      recorder && recorder.record();
      console.log("recording...");
    }

    function upload(transcript) {
      // Create WAV File as Blob and upload Blob
      recorder && recorder.exportWAV(function(blob) {
        var reader = new FileReader();
        reader.onload = function(event){
          $.ajax({
            url: 'upload.php',
            type: 'POST',
            data: { 'transcript': transcript, 'data': event.target.result },
            dataType: 'text'
          }).done(function(data) {
              //console.log(data);
              $.each(JSON.parse(data), function(i,item){
                create("sound" + item[i], item.file)
                var test = item.file;
                console.log(item[i]);
                })
          });
        };
        reader.readAsDataURL(blob);
      });

      recorder.clear();
      
      mute();
    }
    
    
    
    
    ////////////////////////////////
    // AUDIO PLAYER
    // Creates Audio Elements when a match is found
    ////////////////////////////////
    
    function create(target, file) {
      // Create Audio Element
      var audio = document.createElement('audio');
          audio.id = target;
          audio.controls = true;
          audio.volume = 1;
          audio.autoplay = true;
          audio.loop = true;
          audio.src = "./files/" + file;
          audio.load();
          audio.play();
      // Append Audio Element to DOM
      var li = document.createElement('li');
          li.appendChild(audio);
          matchedSoundsList.appendChild(li);
    }
    
    function destroy() {
      $("#matchedSoundsList").empty();
    }
    
    function mute() {
      $("audio").each(function(){
          var status = $(this).prop("muted");
          $(this).prop("muted",!status);
      });
      var status = $("#startRecognition").prop("disabled");
      $("#startRecognition").prop("disabled",!status);
    }
    
    
  
  </script>
</body>
</html>
